{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024f877c-4200-4ff2-aaa5-216a060ef889",
   "metadata": {},
   "source": [
    "## Initialize Spark Environment and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5ab1ef3-4bf3-40b2-9bc7-6524f34c45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/shahayush954/spark-3.4.1-bin-hadoop3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07cab299-9fa7-4f50-85e3-b40e4bfb3d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/13 19:29:08 WARN Utils: Your hostname, ubuntu-22 resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)\n",
      "23/08/13 19:29:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/13 19:29:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/08/13 19:29:14 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('missing').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bfe3eca-104f-4cdc-8e50-980240f2cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('ContainsNull.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75c12a8-4967-4171-b2ae-887f49cf377e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbcbdaf-2cf1-473a-be3a-8f11d70bbaf3",
   "metadata": {},
   "source": [
    "## Missing Data Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d6e4dcb-ad12-4a1f-96b8-ed46b03823bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop().show() # drop if row has any missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01ead722-684a-4388-97e2-c81d6f653c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(thresh=2).show() # drop the row if it has 2 or more than 2 null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef8313c9-dff8-440f-99e9-591912afbb92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='any').show() # drop the row if any of the value is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80346571-e2ef-4b69-a59d-628455c02346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John| null|\n",
      "|emp2| null| null|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(how='all').show() # drop the row if all the values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77255b21-a325-41b6-80ed-3e074c6234e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.drop(subset=['Sales']).show() # drop the row if the provided list of columns are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "693dac26-333c-4230-92d4-9aa2ab778f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+-----+\n",
      "|  Id|      Name|Sales|\n",
      "+----+----------+-----+\n",
      "|emp1|      John| null|\n",
      "|emp2|Fill Value| null|\n",
      "|emp3|Fill Value|345.0|\n",
      "|emp4|     Cindy|456.0|\n",
      "+----+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('Fill Value').show() # replace any string cloumn with null value with the given string value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ce08f7-0749-44a1-8fa0-e12163593058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|  0.0|\n",
      "|emp2| null|  0.0|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill(0).show() # replace any numeric cloumn with null value with the given numeric value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "756307b6-7225-44f4-bb9d-e7c3512221d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----+\n",
      "|  Id|   Name|Sales|\n",
      "+----+-------+-----+\n",
      "|emp1|   John| null|\n",
      "|emp2|No Name| null|\n",
      "|emp3|No Name|345.0|\n",
      "|emp4|  Cindy|456.0|\n",
      "+----+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('No Name', subset=['Name']).show() # using replace value with subset to specify which column to use which value for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daab0d33-66b9-4ddd-b1af-18f2a8e46c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|  Id| Name|Sales|\n",
      "+----+-----+-----+\n",
      "|emp1| John|400.5|\n",
      "|emp2| null|400.5|\n",
      "|emp3| null|345.0|\n",
      "|emp4|Cindy|456.0|\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Filling null Sales value with mean value\n",
    "from pyspark.sql.functions import mean\n",
    "mean_val = df.select(mean(df['Sales'])).collect()\n",
    "mean_sales = mean_val[0][0]\n",
    "df.na.fill(mean_sales, subset=['Sales']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209ffb6-cd3c-43c3-96fb-a307a39d4b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
